{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3481e1f-dfb4-49a1-9b90-6c45e14547d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huayu/anaconda3/envs/LLM/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8aaa62-7684-49ab-9ad1-3f0a9ad8f380",
   "metadata": {},
   "source": [
    "# Load Qwen2-VL-7B-Instruct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b88a4b7-dc0e-4806-9fa3-db2331561144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:11<00:00,  2.27s/it]\n"
     ]
    }
   ],
   "source": [
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-7B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load the processor\n",
    "min_pixels = 1000000\n",
    "max_pixels = 1000000\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-7B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels\n",
    ")\n",
    "\n",
    "STAGES = ['Wake', 'N1', 'N2', 'N3', 'REM']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d02e6c-eca9-48d9-a457-716de692b483",
   "metadata": {},
   "source": [
    "# Load images generated based on ConMIL interpretations and prediction sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5096226f-cc3c-49d6-ac9f-a85df4758c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prediction set figures\n",
    "sample_path = 'sleepEDF'\n",
    "\n",
    "# Load ground truth and prediction set\n",
    "gt_path = os.path.join(sample_path, \"ground_truth.txt\")\n",
    "with open(gt_path, \"r\") as f:\n",
    "    gt_text = f.read().strip()\n",
    "    gt = STAGES.index(gt_text.split(\":\")[1].strip())\n",
    "\n",
    "prediction_set = [fname.replace(\".png\", \"\") for fname in os.listdir(sample_path) if fname.endswith(\".png\") and fname != \"org.png\"]\n",
    "pset_indices = [STAGES.index(code) for code in prediction_set]\n",
    "\n",
    "# Load images for predictions\n",
    "conmil_paths = [os.path.join(sample_path, f\"{STAGES[idx]}.png\") for idx in pset_indices]\n",
    "images = [Image.open(path).convert(\"RGB\") for path in conmil_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41014f6-b09e-4558-9540-d477367a8537",
   "metadata": {},
   "source": [
    "# Generate instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f9c5639-994b-42a8-874f-8f1163cdfba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dynamic instruction\n",
    "diagnosis_options = \", \".join([STAGES[idx] for idx in sorted(pset_indices)])\n",
    "instruction = (\n",
    "    f\"Given a Fpz-Cz EEG and visual interpretations for the following possible sleep stages: {diagnosis_options}, \"\n",
    "    f\"determine the most likely sleep stage. Use the provided model interpretations as reference and \"\n",
    "    f\"base your decision solely on these visual features without additional analysis or introducing new criteria.\\n\\n\"\n",
    "    f\"Provide your answer in the following format:\\n\"\n",
    "    f\"Conclusion: <Selected Sleep Stage>\\n\"\n",
    "    f\"Reason: <Brief reason for the choice based on visual features>\"\n",
    ")\n",
    "\n",
    "# Prepare messages for the processor\n",
    "content = [{\"type\": f\"Model interpretation for sleep stage: {STAGES[idx]}\", \"image\": img} for idx, img in zip(pset_indices, images)]\n",
    "content.append({\"type\": \"Instruction\", \"text\": instruction})\n",
    "messages = [{\"role\": \"user\", \"content\": content}]\n",
    "\n",
    "# Process vision info and prepare inputs\n",
    "text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=[image_inputs],\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")  # Move inputs to GPU if using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a92de38d-e252-4886-964c-eb2da7c4ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=512)\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    ")\n",
    "\n",
    "# Parse LLM response\n",
    "response = output_text[0].strip()\n",
    "diagnosis = response.split(\"Conclusion: \")[1].split(\"\\n\")[0].strip() if \"Conclusion: \" in response else \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f3ab7-ab41-4c38-97b8-4c9be8e61bfe",
   "metadata": {},
   "source": [
    "# Show LLM response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20304033-3deb-468d-8b8d-75e442f70726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Given a Fpz-Cz EEG and visual interpretations for the following possible sleep stages: Wake, N1, REM, determine the most likely sleep stage. Use the provided model interpretations as reference and base your decision solely on these visual features without additional analysis or introducing new criteria.\n",
      "\n",
      "Provide your answer in the following format:\n",
      "Conclusion: <Selected Sleep Stage>\n",
      "Reason: <Brief reason for the choice based on visual features>\n",
      "Generated Response: Conclusion: N1\n",
      "Reason: The EEG trace shows a relatively low amplitude with some theta waves, which is characteristic of the N1 sleep stage. The green bars indicate the model's attention overlay, which aligns with the N1 stage.\n",
      "Extracted Conclusion: N1\n",
      "Ground Truth: N1\n"
     ]
    }
   ],
   "source": [
    "print(\"Instruction:\", instruction)\n",
    "print(\"Generated Response:\", response)\n",
    "print(\"Extracted Conclusion:\", diagnosis)\n",
    "print(\"Ground Truth:\", STAGES[gt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f3750f-7068-48b9-a9ec-a7a62df2e873",
   "metadata": {},
   "source": [
    "# Now we see how LLM works without ConMIL's support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fb31529-61f1-4034-9b3a-ec4f0325a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original image\n",
    "org_image_path = os.path.join(sample_path, \"org.png\")\n",
    "org_image = Image.open(org_image_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "192c8f4d-8b10-4061-82a5-1eeb789b3b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instruction\n",
    "instruction = (\n",
    "    f\"Given a Fpz-Cz EEG, determine the most likely sleep stage among the following categories:\"\n",
    "    f\"Wake, N1, N2, N3, or REM.\"\n",
    "    f\"Base your decision solely on the visual features of the provided EEG without performing additional analysis or introducing new criteria.\\n\\n\"\n",
    "    f\"Provide your answer in the following format:\\n\"\n",
    "    f\"Conclusion: <Selected Sleep Stage>\\n\"\n",
    "    f\"Reason: <Brief reason for the choice based on visual features>\"\n",
    ")\n",
    "\n",
    "# Prepare messages for the processor\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"EEG plot\", \"image\": org_image},\n",
    "            {\"type\": \"Instruction\", \"text\": instruction},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Process vision info and prepare inputs\n",
    "text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=[image_inputs],\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")  # Move inputs to GPU if using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39951344-57b0-43fc-8dc9-1b03df66a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=512)\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    ")\n",
    "\n",
    "# Parse LLM response\n",
    "response = output_text[0].strip()\n",
    "diagnosis = response.split(\"Conclusion: \")[1].split(\"\\n\")[0].strip() if \"Conclusion: \" in response else \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4422de0e-523c-4323-bf85-3b0aa7d8a2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Given a Fpz-Cz EEG, determine the most likely sleep stage among the following categories:Wake, N1, N2, N3, or REM.Base your decision solely on the visual features of the provided EEG without performing additional analysis or introducing new criteria.\n",
      "\n",
      "Provide your answer in the following format:\n",
      "Conclusion: <Selected Sleep Stage>\n",
      "Reason: <Brief reason for the choice based on visual features>\n",
      "Generated Response: Conclusion: N2\n",
      "Reason: The EEG shows a relatively smooth and regular pattern with occasional small amplitude fluctuations, which is characteristic of stage N2 sleep.\n",
      "Extracted Diagnosis: N2\n",
      "Ground Truth: N1\n"
     ]
    }
   ],
   "source": [
    "print(\"Instruction:\", instruction)\n",
    "print(\"Generated Response:\", response)\n",
    "print(\"Extracted Diagnosis:\", diagnosis)\n",
    "print(\"Ground Truth:\", STAGES[gt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5045fc8-bdcb-4b58-8129-2ccb9b6fb688",
   "metadata": {},
   "source": [
    "# We can also see how LLM works with only ConMIL prediction set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e817e3bc-5915-4194-b49c-8c8083c6925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instruction\n",
    "instruction = (\n",
    "    f\"Given a Fpz-Cz EEG, determine the most likely sleep stage among the following categories:\"\n",
    "    f\"{diagnosis_options}\"\n",
    "    f\"Base your decision solely on the visual features of the provided EEG without performing additional analysis or introducing new criteria.\\n\\n\"\n",
    "    f\"Provide your answer in the following format:\\n\"\n",
    "    f\"Conclusion: <Selected Sleep Stage>\\n\"\n",
    "    f\"Reason: <Brief reason for the choice based on visual features>\"\n",
    ")\n",
    "\n",
    "# Prepare messages for the processor\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"EEG plot\", \"image\": org_image},\n",
    "            {\"type\": \"Instruction\", \"text\": instruction},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Process vision info and prepare inputs\n",
    "text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=[image_inputs],\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")  # Move inputs to GPU if using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7d63d0e-c4c2-45f1-ab35-94baac0c2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=512)\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    ")\n",
    "\n",
    "# Parse LLM response\n",
    "response = output_text[0].strip()\n",
    "diagnosis = response.split(\"Conclusion: \")[1].split(\"\\n\")[0].strip() if \"Conclusion: \" in response else \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0810c532-b224-47ef-9208-6c4d9528a3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Given a Fpz-Cz EEG, determine the most likely sleep stage among the following categories:Wake, N1, REMBase your decision solely on the visual features of the provided EEG without performing additional analysis or introducing new criteria.\n",
      "\n",
      "Provide your answer in the following format:\n",
      "Conclusion: <Selected Sleep Stage>\n",
      "Reason: <Brief reason for the choice based on visual features>\n",
      "Generated Response: Conclusion: Wake\n",
      "Reason: The EEG shows a high level of variability and irregularity, with no clear patterns or consistent waveforms that are characteristic of sleep stages such as N1, N2, or REM. The absence of a consistent pattern and the high level of noise suggest that the individual was likely awake during the recording.\n",
      "Extracted Diagnosis: Wake\n",
      "Ground Truth: N1\n"
     ]
    }
   ],
   "source": [
    "print(\"Instruction:\", instruction)\n",
    "print(\"Generated Response:\", response)\n",
    "print(\"Extracted Diagnosis:\", diagnosis)\n",
    "print(\"Ground Truth:\", STAGES[gt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2359539a-3236-4eca-9393-8ef48f482860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b3ebc-5f94-4c5c-b6b0-52bf356f7980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
